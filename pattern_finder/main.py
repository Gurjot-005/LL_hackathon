# main.py

import os
import numpy as np

from config import (
    DATA_PATH,
    PROCESSED_DATA_PATH,
    CORRELATION_THRESHOLD,
    OUTPUT_DIR
)

from data_handler import RawFileDataHandler
from cleaned_csv_handler import CleanedCSVFolderHandler
from loss_vector_builder import LossVectorBuilder
from correlation_engine import CorrelationEngine
from clustering_engine import ClusteringEngine
from confidence import compute_confidence
from exporter import export_topology
from validator import LinkValidator
from visualization import Visualizer


def main(dataset_mode="raw"):
    print("ðŸ“¡ Nokia Fronthaul Pattern Finder Starting...\n")

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # Choose data source
    if dataset_mode == "processed":
        handler = CleanedCSVFolderHandler(PROCESSED_DATA_PATH)
        dataset_label = "processed"
    else:
        handler = RawFileDataHandler(DATA_PATH)
        dataset_label = "raw"

    cells = handler.get_cells()
    print(f"Found {len(cells)} cells")

    if len(cells) < 2:
        print("âš ï¸ Not enough cells for topology inference")
        return

    # Build loss vectors
    print("ðŸ§  Building behavior fingerprints...")
    vectors = LossVectorBuilder(handler).build()
    np.save(f"{OUTPUT_DIR}/loss_vectors.npy", vectors)

    # Correlation
    print("ðŸ“Š Computing correlation matrix...")
    corr_df = CorrelationEngine(CORRELATION_THRESHOLD).compute_matrix(vectors)
    corr_df.to_csv(f"{OUTPUT_DIR}/corr_matrix.csv")

    # Clustering
    print("ðŸ•¸ï¸ Inferring topology...")
    link_map = ClusteringEngine(CORRELATION_THRESHOLD).cluster(corr_df)

    # Confidence
    print("ðŸ“ Computing confidence scores...")
    confidences = compute_confidence(link_map, corr_df)

    # Validation
    print("âœ… Validating results...")
    issues = LinkValidator().validate(link_map)

    # Visualization
    viz = Visualizer()

    print("ðŸŽ¨ Generating heatmap...")
    viz.save_heatmap(corr_df, f"{OUTPUT_DIR}/heatmap.png")

    print("ðŸ•¸ï¸ Generating topology graph...")
    viz.save_topology_graph(
        link_map,
        confidences,
        f"{OUTPUT_DIR}/topology_graph.png"
    )

    # Export
    print("ðŸ’¾ Exporting topology...")
    export_topology(
        f"{OUTPUT_DIR}/topology.json",
        link_map,
        confidences,
        CORRELATION_THRESHOLD,
        dataset_label,
        len(cells)
    )

    print("\nðŸ DONE â€” Network Topology Discovered\n")
    for link, cells in link_map.items():
        print(f"{link}: {cells}")

    if issues:
        print("\nâš ï¸ Warnings:")
        for issue in issues:
            print("-", issue)


if __name__ == "__main__":
    main()
